{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "242dedff-16b2-41e9-a010-c2722aad9104",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "77cb3d59-4ec4-4697-8365-1ebf76ed23a3",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'arc_chall.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[33m'\u001b[39m\u001b[33marc_easy.json\u001b[39m\u001b[33m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m train_file:\n\u001b[32m      2\u001b[39m     ez = json.load(train_file)\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43marc_chall.json\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m train_file:\n\u001b[32m      4\u001b[39m     ch = json.load(train_file)\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[33m'\u001b[39m\u001b[33mopenbookqa.json\u001b[39m\u001b[33m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m train_file:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\miniforge3\\envs\\tinker\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:343\u001b[39m, in \u001b[36m_modified_open\u001b[39m\u001b[34m(file, *args, **kwargs)\u001b[39m\n\u001b[32m    336\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[32m0\u001b[39m, \u001b[32m1\u001b[39m, \u001b[32m2\u001b[39m}:\n\u001b[32m    337\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    338\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mIPython won\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m by default \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    339\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    340\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33myou can use builtins\u001b[39m\u001b[33m'\u001b[39m\u001b[33m open.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    341\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m343\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'arc_chall.json'"
     ]
    }
   ],
   "source": [
    "with open('arc_easy.json') as train_file:\n",
    "    ez = json.load(train_file)\n",
    "with open('arc_chall.json') as train_file:\n",
    "    ch = json.load(train_file)\n",
    "with open('openbookqa.json') as train_file:\n",
    "    qa = json.load(train_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ed8adf63-f40a-4abf-8fc0-62dd8a65e714",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m df_easy = pd.DataFrame(ez)\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m df_chall = pd.DataFrame(\u001b[43mch\u001b[49m)\n\u001b[32m      3\u001b[39m df_openbook = pd.DataFrame(qa)\n",
      "\u001b[31mNameError\u001b[39m: name 'ch' is not defined"
     ]
    }
   ],
   "source": [
    "df_easy = pd.DataFrame(ez)\n",
    "df_chall = pd.DataFrame(ch)\n",
    "df_openbook = pd.DataFrame(qa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "29397873-8b01-4a44-93a4-2d22b3a473cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def get_correct_choice_label(question_str, answer):\n",
    "    \"\"\"\n",
    "    Given a question string with choices and the correct answer,\n",
    "    returns the corresponding choice label (e.g., 'B' or '2').\n",
    "    Works for both lettered and numbered labels.\n",
    "    \"\"\"\n",
    "    if type(answer) == list:\n",
    "        answer = answer[0]\n",
    "    # Extract the part after \"Choices:\"\n",
    "    match = re.search(r\"Choices:\\s*(.*)\", question_str)\n",
    "    if not match:\n",
    "        return None\n",
    "\n",
    "    choices_part = match.group(1)\n",
    "    # Split choices and strip spaces\n",
    "    choices = [c.strip() for c in choices_part.split('|')]\n",
    "\n",
    "    for choice in choices:\n",
    "        # Match labels that are letters or numbers before a period\n",
    "        label_match = re.match(r\"([A-Za-z0-9]+)\\.\\s*(.*)\", choice)\n",
    "        if label_match:\n",
    "            label, text = label_match.groups()\n",
    "            # Normalize and compare answer text\n",
    "            if text.strip().lower() == answer.strip().lower():\n",
    "                return label.lower()\n",
    "\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d087e0b9-f4ad-44d4-a264-944e2bc989c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleandf(df):\n",
    "    accdf = df[['question', 'answer', 'rewrite_all_ans']]\n",
    "    if type(accdf['answer'][0]) == list:\n",
    "        accdf =  accdf.assign(answer = accdf['answer'].apply(lambda x: x[0]))\n",
    "    accdf = accdf.assign(answer_letter = df.apply(lambda r: get_correct_choice_label(r[\"question\"], r['answer']), axis = 1))\n",
    "    return accdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5b4aba3b-b6cf-4000-9be1-7bc2bfab7f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accc(row):\n",
    "    correct = row['answer'].lower()\n",
    "    correct = re.sub(r'[^a-zA-Z0-9\\s]+', '', correct)\n",
    "    correct_letter = row['answer_letter']\n",
    "    out = [0,0]\n",
    "    lst = row['rewrite_all_ans']\n",
    "    for l in lst:\n",
    "        for ans in l:\n",
    "            if correct in ans or ans == correct_letter or ans == f'boxed{correct_letter}':\n",
    "                out[0] = out[0] + 1\n",
    "            out[1] = out[1] + 1\n",
    "    return out\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d5d90b17-bc94-45ad-a2df-8297c2b340d0",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_chall' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[21]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m df_easy = cleandf(df_easy)\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m df_chall = cleandf(\u001b[43mdf_chall\u001b[49m)\n\u001b[32m      3\u001b[39m df_openbook = cleandf(df_openbook)\n",
      "\u001b[31mNameError\u001b[39m: name 'df_chall' is not defined"
     ]
    }
   ],
   "source": [
    "df_easy = cleandf(df_easy)\n",
    "df_chall = cleandf(df_chall)\n",
    "df_openbook = cleandf(df_openbook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5045e361-f950-46d4-9623-305048dca903",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello World 123 Python Program\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def remove_non_alphanumeric_except_space(text):\n",
    "    \"\"\"\n",
    "    Removes all characters from a string that are not alphanumeric or a space.\n",
    "\n",
    "    Args:\n",
    "        text (str): The input string.\n",
    "\n",
    "    Returns:\n",
    "        str: The string with only alphanumeric characters and spaces.\n",
    "    \"\"\"\n",
    "    # The regex pattern `[^a-zA-Z0-9\\s]+` matches one or more characters\n",
    "    # that are NOT (^) lowercase letters (a-z), uppercase letters (A-Z),\n",
    "    # digits (0-9), or whitespace characters (\\s).\n",
    "    # These matched characters are replaced with an empty string.\n",
    "    cleaned_text = re.sub(r'[^a-zA-Z0-9\\s]+', '', text)\n",
    "    return cleaned_text\n",
    "\n",
    "# Example usage:\n",
    "input_string = \"Hello, World! 123 @Python$ Program.\"\n",
    "output_string = remove_non_alphanumeric_except_space(input_string)\n",
    "print(output_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ff0d5827-3215-4306-8d31-be462347effb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from itertools import chain\n",
    "\n",
    "def _flatten(nested):\n",
    "    \"\"\"Recursively flatten arbitrarily nested lists/tuples.\"\"\"\n",
    "    for x in nested:\n",
    "        if isinstance(x, (list, tuple)):\n",
    "            yield from _flatten(x)\n",
    "        else:\n",
    "            yield x\n",
    "\n",
    "# Compile a few regexes to robustly catch the first answer letter near the start.\n",
    "# Handles:\n",
    "#   \"c\", \"b reason...\", \"boxedc\", \"boxed c\", \"answer b ...\", \"[boxedc, c, ...]\"\n",
    "# We ONLY accept a/b/c/d; anything else is ignored.\n",
    "_PATTERNS = [\n",
    "    re.compile(r'^\\s*(?:boxed)?\\s*([abcd])\\b', re.IGNORECASE),     # \"c\", \"boxedc\", \"boxed c\"\n",
    "    re.compile(r'^\\s*answer\\s*([abcd])\\b', re.IGNORECASE),         # \"answer b ...\"\n",
    "    re.compile(r'^\\s*\\[?\\s*(?:boxed)?\\s*([abcd])\\b', re.IGNORECASE) # leading bracketed tokens\n",
    "]\n",
    "\n",
    "def _extract_letter(s: str):\n",
    "    \"\"\"Return 'a'/'b'/'c'/'d' if a clear leading vote is present, else None.\"\"\"\n",
    "    if not isinstance(s, str):\n",
    "        s = str(s)\n",
    "    s = s.strip()\n",
    "    for pat in _PATTERNS:\n",
    "        m = pat.search(s)\n",
    "        if m:\n",
    "            letter = m.group(1).lower()\n",
    "            if letter in {'a','b','c','d'}:\n",
    "                return letter\n",
    "    # Fallback: sometimes the very first token is just 'a'/'b'/'c'/'d' with punctuation\n",
    "    m = re.match(r'^([abcd])\\W', s.lower())\n",
    "    if m:\n",
    "        return m.group(1)\n",
    "    return None\n",
    "\n",
    "def rewrites_to_percent_matrix(df: pd.DataFrame, rewrites_col='rewrite_all_ans'):\n",
    "    \"\"\"\n",
    "    For each row, look at all strings in `rewrites_col` (list-of-lists of strings),\n",
    "    tally how many indicate A/B/C/D, and return a (n_rows x 4) NumPy array of percentages.\n",
    "    Order of columns: [A, B, C, D].\n",
    "    \"\"\"\n",
    "    out = np.zeros((len(df), 4), dtype=float)\n",
    "    idx_map = {'a':0, 'b':1, 'c':2, 'd':3}\n",
    "\n",
    "    for i, rewrites in enumerate(df[rewrites_col].tolist()):\n",
    "        # Flatten any nesting and keep only strings\n",
    "        flat = list(_flatten(rewrites if isinstance(rewrites, (list, tuple)) else [rewrites]))\n",
    "        votes = []\n",
    "        for item in flat:\n",
    "            letter = _extract_letter(item)\n",
    "            if letter is not None:\n",
    "                votes.append(letter)\n",
    "\n",
    "        total = len(votes)\n",
    "        if total > 0:\n",
    "            c = Counter(votes)\n",
    "            row = np.array([\n",
    "                c.get('a', 0) / total,\n",
    "                c.get('b', 0) / total,\n",
    "                c.get('c', 0) / total,\n",
    "                c.get('d', 0) / total,\n",
    "            ], dtype=float)\n",
    "            out[i, :] = row\n",
    "        # else: leave zeros if no recognizable votes\n",
    "    return out\n",
    "\n",
    "# --- Example usage ---\n",
    "# matrix = rewrites_to_percent_matrix(df_chall, 'rewrite_all_ans')\n",
    "# matrix.shape  # (n_rows, 4), columns correspond to [A, B, C, D]\n",
    "# matrix[0]     # e.g. array([0.5, 0.5, 0. , 0. ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f5159e09-1594-4dcc-afd9-693cbdb0ad40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertnums(l):\n",
    "    if l == 'a':\n",
    "        return 0\n",
    "    elif l == 'b':\n",
    "        return 1\n",
    "    elif l == 'c':\n",
    "        return 2\n",
    "    return 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7d5f9406-131e-4ca0-87f2-cb809e5fe9b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binary ECE: 0.2908430460849268\n",
      "Multiclass ECE: 0.1991652344302426\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def _bin_indices(conf, n_bins=15, strategy=\"uniform\"):\n",
    "    \"\"\"\n",
    "    Returns bin edges and the bin index for each confidence.\n",
    "    strategy: \"uniform\" -> equal-width bins in [0,1]\n",
    "              \"quantile\" -> equal-count bins (uses ranks)\n",
    "    \"\"\"\n",
    "    conf = np.asarray(conf)\n",
    "    eps = 1e-12\n",
    "    if strategy == \"uniform\":\n",
    "        edges = np.linspace(0.0, 1.0, n_bins + 1)\n",
    "        # place exactly-1.0 into last bin\n",
    "        idx = np.minimum(np.digitize(conf, edges, right=False) - 1, n_bins - 1)\n",
    "    elif strategy == \"quantile\":\n",
    "        # quantile edges; ensure unique and covering [0,1]\n",
    "        qs = np.linspace(0, 1, n_bins + 1)\n",
    "        edges = np.quantile(conf, qs)\n",
    "        # handle potential duplicates (e.g., many identical confidences)\n",
    "        # add tiny jitter to make edges strictly increasing\n",
    "        for i in range(1, len(edges)):\n",
    "            if edges[i] <= edges[i-1]:\n",
    "                edges[i] = np.nextafter(edges[i-1], 1.0)\n",
    "        idx = np.minimum(np.digitize(conf, edges, right=False) - 1, n_bins - 1)\n",
    "        idx = np.maximum(idx, 0)\n",
    "    else:\n",
    "        raise ValueError(\"strategy must be 'uniform' or 'quantile'\")\n",
    "    return edges, idx\n",
    "\n",
    "def ece_binary(y_true, y_prob, n_bins=15, strategy=\"uniform\", return_bins=False):\n",
    "    \"\"\"\n",
    "    ECE for binary classification.\n",
    "    y_true: shape (N,), values in {0,1}\n",
    "    y_prob: shape (N,), predicted probability for the positive class (class=1)\n",
    "    \"\"\"\n",
    "    y_true = np.asarray(y_true).astype(int)\n",
    "    y_prob = np.asarray(y_prob)\n",
    "    assert y_true.shape == y_prob.shape\n",
    "\n",
    "    edges, idx = _bin_indices(y_prob, n_bins, strategy)\n",
    "    N = len(y_true)\n",
    "\n",
    "    ece = 0.0\n",
    "    bin_stats = []\n",
    "    for b in range(n_bins):\n",
    "        mask = (idx == b)\n",
    "        n_b = mask.sum()\n",
    "        if n_b == 0:\n",
    "            bin_stats.append((b, 0, np.nan, np.nan))\n",
    "            continue\n",
    "        acc_b = np.mean(y_true[mask] == 1)\n",
    "        conf_b = np.mean(y_prob[mask])\n",
    "        ece += (n_b / N) * abs(acc_b - conf_b)\n",
    "        bin_stats.append((b, n_b, acc_b, conf_b))\n",
    "\n",
    "    if return_bins:\n",
    "        # returns list of tuples: (bin_id, count, accuracy, confidence)\n",
    "        return float(ece), bin_stats, edges\n",
    "    return float(ece)\n",
    "\n",
    "def ece_multiclass(y_true, y_proba, n_bins=15, strategy=\"uniform\", return_bins=False):\n",
    "    \"\"\"\n",
    "    ECE for multiclass classification (K classes).\n",
    "    y_true: shape (N,), int labels in [0, K-1]\n",
    "    y_proba: shape (N, K), row i sums to 1\n",
    "    Uses the standard definition with confidence = probability of the true class.\n",
    "    \"\"\"\n",
    "    y_true = np.asarray(y_true).astype(int)\n",
    "    y_proba = np.asarray(y_proba)\n",
    "    N, K = y_proba.shape\n",
    "    assert y_true.shape[0] == N\n",
    "\n",
    "    # confidence for the true class\n",
    "    conf_true = y_proba[np.arange(N), y_true]\n",
    "    correct = (np.argmax(y_proba, axis=1) == y_true).astype(int)\n",
    "\n",
    "    edges, idx = _bin_indices(conf_true, n_bins, strategy)\n",
    "\n",
    "    ece = 0.0\n",
    "    bin_stats = []\n",
    "    for b in range(n_bins):\n",
    "        mask = (idx == b)\n",
    "        n_b = mask.sum()\n",
    "        if n_b == 0:\n",
    "            bin_stats.append((b, 0, np.nan, np.nan))\n",
    "            continue\n",
    "        acc_b = np.mean(correct[mask])\n",
    "        conf_b = np.mean(conf_true[mask])\n",
    "        ece += (n_b / N) * abs(acc_b - conf_b)\n",
    "        bin_stats.append((b, n_b, acc_b, conf_b))\n",
    "\n",
    "    if return_bins:\n",
    "        return float(ece), bin_stats, edges\n",
    "    return float(ece)\n",
    "\n",
    "# -------------------------\n",
    "# Example usage\n",
    "# -------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    rng = np.random.default_rng(0)\n",
    "    # Binary\n",
    "    y = rng.integers(0, 2, size=1000)\n",
    "    p = np.clip(rng.beta(2, 5, size=1000), 0, 1)\n",
    "    print(\"Binary ECE:\", ece_binary(y, p, n_bins=15, strategy=\"uniform\"))\n",
    "\n",
    "    # Multiclass\n",
    "    N, K = 1000, 4\n",
    "    logits = rng.normal(size=(N, K))\n",
    "    proba = np.exp(logits) / np.exp(logits).sum(axis=1, keepdims=True)\n",
    "    y_mc = rng.integers(0, K, size=N)\n",
    "    print(\"Multiclass ECE:\", ece_multiclass(y_mc, proba, n_bins=15, strategy=\"quantile\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "57c83def-7e7b-4540-9c99-c77a55bd11be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stats(df):\n",
    "    #accuracy \n",
    "    b = df.apply(get_accc, axis = 1).values\n",
    "    count = 0\n",
    "    total = 0\n",
    "    for i in b: \n",
    "        count += i[0]\n",
    "        total += i[1]\n",
    "    acc = count / total\n",
    "        \n",
    "    df_percents = rewrites_to_percent_matrix(df)\n",
    "    correct = [convertnums(i) for i in df['answer_letter'].values]\n",
    "    ece =  ece_multiclass(chall_correct, df_chall_percents, n_bins=5)\n",
    "    print(f\"accuracy: {acc}, ece: {ece}\")\n",
    "    return acc, ece\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8ec14d69-ce1e-4770-bb2a-ff4e06bb25eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.738, ece: 0.12903791610688167\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.738, 0.12903791610688167)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_stats(df_easy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6714d13-0478-4138-bde3-5609993f82f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_stats(df_chall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4beae277-f80a-4057-a022-e06301fa768e",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_stats(df_openbook)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
